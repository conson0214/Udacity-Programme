{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型\n",
    "## 1. 单模型训练  \n",
    "单模型训练, 我们采用的是keras库提供的InceptionV3, ResNet50, InceptionResNetV2三个模型\n",
    "\n",
    "数据集下载：https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 载入必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "from keras.callbacks import *\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import math\n",
    "import os\n",
    "import datetime\n",
    "import pydot\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义检查路径函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_path_gen():\n",
    "    if not(os.path.exists('./Weights')):\n",
    "        os.mkdir('Weights')\n",
    "    if not(os.path.exists('./Tensor_log')):\n",
    "        os.mkdir('Tensor_log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_cat_dog(MODEL, image_size):\n",
    "    # hyper-parameters\n",
    "    bs = 16\n",
    "\n",
    "    width = image_size[0]\n",
    "    height = image_size[1]\n",
    "    input_tensor = Input((height, width, 3))\n",
    "    x = input_tensor\n",
    "    \n",
    "    base_model = MODEL(input_tensor=x, weights='imagenet', include_top=False)\n",
    "\n",
    "    # 搭建tranfer learning的最后一层\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(base_model.input, x)\n",
    "    model.compile(optimizer='adadelta',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # 获取训练数据\n",
    "    np.random.seed(2017)\n",
    "\n",
    "    n = 25000\n",
    "    X = np.zeros((n, image_size[0], image_size[1], 3), dtype=np.uint8)\n",
    "    y = np.zeros((n, 1), dtype=np.uint8)\n",
    "    X_file = 'X' + str(image_size[0]) + '.npy'\n",
    "    y_file = 'y' + str(image_size[0]) + '.npy'\n",
    "\n",
    "    if os.path.exists(X_file) and os.path.exists(y_file):\n",
    "        X = np.load(X_file)\n",
    "        y = np.load(y_file)\n",
    "    else:\n",
    "        for i in tqdm(range(int(n/2))):\n",
    "            X[i] = cv2.resize(cv2.imread('//Dataset/train/cat/cat.%d.jpg' % i), (image_size[0], image_size[1]))\n",
    "            X[i+int(n/2)] = cv2.resize(cv2.imread('/Dataset/train/dog/dog.%d.jpg' % i), (image_size[0], image_size[1]))\n",
    "        y[int(n/2):] = 1\n",
    "        np.save(X_file, X)\n",
    "        np.save(y_file, y)\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "    train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "    val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "    train_generator = train_datagen.flow(X_train, y_train, batch_size=bs)\n",
    "    val_generator = val_datagen.flow(X_valid, y_valid, batch_size=bs)\n",
    "\n",
    "    # callbacks\n",
    "    best_weights_path = os.path.join('./Weights', MODEL.__name__)\n",
    "    if not(os.path.exists(best_weights_path)):\n",
    "        os.mkdir(best_weights_path)\n",
    "    best_weights_filepath = os.path.join(best_weights_path, 'best_weights')\n",
    "\n",
    "    log_path = os.path.join('./Tensor_log', MODEL.__name__)\n",
    "    if not (os.path.exists(log_path)):\n",
    "        os.mkdir(log_path)\n",
    "\n",
    "    earlyStopping = EarlyStopping(monitor='val_loss', patience=20, verbose=1, mode='auto')\n",
    "    saveBestModel = ModelCheckpoint(best_weights_filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=1/math.e, verbose=1, patience=10, min_lr=0.0001)\n",
    "    tensorboard = TensorBoard(log_dir=log_path)\n",
    "\n",
    "    # 训练\n",
    "    model.fit_generator(train_generator, steps_per_epoch=1000, epochs=10, validation_data=val_generator,\n",
    "                        verbose=2, callbacks=[earlyStopping, saveBestModel, reduce_lr, tensorboard])W\n",
    "    model.save(MODEL.__name__ + '_cvd.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 执行训练过程, 统计训练时间并生成固化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "check_path_gen()\n",
    "\n",
    "# tick tock start\n",
    "starttime = datetime.datetime.now()\n",
    "train_cat_dog(InceptionV3, (299, 299))\n",
    "endtimeV3 = datetime.datetime.now()\n",
    "\n",
    "train_cat_dog(ResNet50, (224, 224))\n",
    "endtimeRes = datetime.datetime.now()\n",
    "\n",
    "train_cat_dog(InceptionResNetV2, (299, 299))\n",
    "endtimeIRV2 = datetime.datetime.now()\n",
    "\n",
    "print('InceptionV3 train time %d seconds' % (endtimeV3-starttime).seconds)\n",
    "print('ResNet50 train time %d seconds' % (endtimeRes-endtimeV3).seconds)\n",
    "print('InceptionResNetV2 train time %d seconds' % (endtimeIRV2-endtimeRes).seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 模型融合训练  \n",
    "将三个模型特征提取出来, 融合在一起, 在加FC层和分类器, 利用集成学习方法训练更强大的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义函数将三个模型的特征分别提取出来并保存成.h5文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_gap(MODEL, image_size, lambda_func=None):\n",
    "    width = image_size[0]\n",
    "    height = image_size[1]\n",
    "    input_tensor = Input((height, width, 3))\n",
    "    x = input_tensor\n",
    "    if lambda_func:\n",
    "        x = Lambda(lambda_func)(x)\n",
    "\n",
    "    base_model = MODEL(input_tensor=x, weights='imagenet', include_top=False)\n",
    "    model = Model(base_model.input, GlobalAveragePooling2D()(base_model.output))\n",
    "\n",
    "    gen = ImageDataGenerator()\n",
    "    train_generator = gen.flow_from_directory(\"./Dataset/train\", image_size, shuffle=False,\n",
    "                                              batch_size=100)\n",
    "    test_generator = gen.flow_from_directory(\"./Dataset/test2\", image_size, shuffle=False,\n",
    "                                             batch_size=100, class_mode=None)\n",
    "\n",
    "    train = model.predict_generator(train_generator, int(train_generator.samples/100))\n",
    "    test = model.predict_generator(test_generator, int(test_generator.samples/100))\n",
    "    with h5py.File(\"gap_%s.h5\" % MODEL.__name__) as h:\n",
    "        h.create_dataset(\"train\", data=train)\n",
    "        h.create_dataset(\"test\", data=test)\n",
    "        h.create_dataset(\"label\", data=train_generator.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提取模型特征的执行过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "starttime = datetime.datetime.now()\n",
    "write_gap(ResNet50, (224, 224))\n",
    "write_gap(InceptionV3, (299, 299), inception_v3.preprocess_input)\n",
    "write_gap(InceptionResNetV2, (299, 299), inception_resnet_v2.preprocess_input)\n",
    "endtime = datetime.datetime.now()\n",
    "print((endtime-starttime).seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练融合模型并固化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "X_test = []\n",
    "\n",
    "starttime = datetime.datetime.now()\n",
    "\n",
    "for filename in [\"gap_ResNet50.h5\", \"gap_InceptionResNetV2.h5\", \"gap_InceptionV3.h5\"]:\n",
    "    with h5py.File(filename, 'r') as h:\n",
    "        X_train.append(np.array(h['train']))\n",
    "        X_test.append(np.array(h['test']))\n",
    "        y_train = np.array(h['label'])\n",
    "\n",
    "X_train = np.concatenate(X_train, axis=1)\n",
    "X_test = np.concatenate(X_test, axis=1)\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "# 训练\n",
    "input_tensor = Input(X_train.shape[1:])\n",
    "x = Dropout(0.5)(input_tensor)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(input_tensor, x)\n",
    "\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "log_path = './model_concat_tensor_log'\n",
    "tensorboard = TensorBoard(log_dir=log_path)\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=128, nb_epoch=8, validation_split=0.2, callbacks=[tensorboard])\n",
    "endtime = datetime.datetime.now()\n",
    "print(\"model concat train time %d seconds\" % (endtime-starttime).seconds)\n",
    "\n",
    "# 模型保存\n",
    "model.save('model_concat_cvd.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型可视化\n",
    "我们利用graphviz写好模型的结构, 观察输入和输出的特征数量和经过的结点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "(graph, ) = pydot.graph_from_dot_file('./graph_model_concat.dot')\n",
    "graph.write('./graph_model_concat.png', format='png')\n",
    "graph_img = cv2.imread('graph_model_concat.png')\n",
    "b, g, r = cv2.split(graph_img)\n",
    "img = cv2.merge([r, g, b])\n",
    "plt.imshow(graph_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
